{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b007233-ee0a-4c5d-8165-4fdba076a8b4",
   "metadata": {},
   "source": [
    "<br>\n",
    "<a href=\"https://www.nvidia.com/en-us/training/\">\n",
    "    <div style=\"width: 55%; background-color: white; margin-top: 50px;\">\n",
    "    <img src=\"https://dli-lms.s3.amazonaws.com/assets/general/nvidia-logo.png\"\n",
    "         width=\"400\"\n",
    "         height=\"186\"\n",
    "         style=\"margin: 0px -25px -5px; width: 300px\"/>\n",
    "</a>\n",
    "<h1 style=\"line-height: 1.4;\"><font color=\"#76b900\"><b>Building Agentic AI Applications with LLMs</h1>\n",
    "<h2><b>Exercise 1:</b> Dataset Chat</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696341b-1f79-4c34-a9e6-ccc5dc411a45",
   "metadata": {},
   "source": [
    "**Welcome back! This is the first exercise in the course, so see what you can do!**\n",
    "\n",
    "This notebook serves as a hands-on exercise following the \"main-lecture\" notebook. The exercises in this series utilizes the same dataset to gradually help us enable more complex LLM interactions.\n",
    "\n",
    "In the previous notebook, we implemented a basic multi-agent system to generate synthetic multi-turn conversations. While useful for generating artificial dialogues, this implementation lacks practicality for end-user applications.\n",
    "\n",
    "### **Learning Objectives:**\n",
    "\n",
    "**In this notebook, we will:**\n",
    "\n",
    "- Build a simple user-facing chatbot that interacts with a dataset.\n",
    "- Address the challenge of handling datasets too large for our model’s context window.\n",
    "- Develop a summarization pipeline to preprocess data efficiently.\n",
    "\n",
    "This dataset will remain in use throughout the course, so our first step is to enable a simple interactive chat with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee8272-833f-4d4b-abce-351bafff3093",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "### **Part 1:** Setting Up A Workshop Assistant Chatbot\n",
    "\n",
    "From the previous exercise, you can specify a simple chatbot that interacts with the user using a simple loop. Based on this, the following function establishes a simple chatbot loop where a user can interact with an AI agent. If no processing function (chain) is provided, it defaults to an unimplemented generator that outputs a placeholder message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a208ed-38b0-4730-a540-0de4e1612f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: status report\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: Chain Not Implemented. Enter with no inputs or interrupt execution to exit."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: \n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "def not_implemented_gen(state):\n",
    "    \"\"\"A placeholder generator that informs users the chain is not yet implemented.\"\"\"\n",
    "    message = \"Chain Not Implemented. Enter with no inputs or interrupt execution to exit.\"\n",
    "    for letter in message:\n",
    "        yield letter\n",
    "        sleep(0.005)\n",
    "\n",
    "def chat_with_chain(state={}, chain=not_implemented_gen):\n",
    "    \"\"\"\n",
    "    Interactive chat function that processes user input through a specified chain.\n",
    "    \n",
    "    Parameters:\n",
    "        state (dict): Maintains chat history and context.\n",
    "        chain (callable): Function to generate responses based on the chat history.\n",
    "    \"\"\"\n",
    "    assert isinstance(state, dict)\n",
    "    state[\"messages\"] = state.get(\"messages\", [])\n",
    "    while True:\n",
    "        try:\n",
    "            human_msg = input(\"\\n[Human]:\")\n",
    "            if not human_msg.strip(): break\n",
    "            agent_msg = \"\"\n",
    "            state[\"messages\"] += [(\"user\", human_msg)]\n",
    "            print(flush=True)\n",
    "            print(\"[Agent]: \", end=\"\", flush=True)\n",
    "            for token in getattr(chain, \"stream\", chain)(state):\n",
    "                agent_msg += token\n",
    "                print(getattr(token, \"content\", token), end=\"\", flush=True)\n",
    "            state[\"messages\"] += [(\"ai\", agent_msg)]\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"KeyboardInterrupt\")\n",
    "            break\n",
    "\n",
    "## Initialize chat with the placeholder generator\n",
    "chat_with_chain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd5d6c-8039-408e-a6cf-ac3081b7fdc7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "From this, we can define a conversational pipeline with an LLM, a prompt template, and a starting state. A prompt, llm, and an output parser are provided, so please combine them together into a chain for your `chat_with_chain` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d974c15-ef48-4b64-9006-331a2530f3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: who are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: I'm a helpful assistant for NVIDIA Deep Learning Institute (DLI). I'm here to assist users with any questions, concerns, or problems related to the workshops and training materials provided by DLI. I can help with installation, configuration, code-related issues, and more! What brings you here today?"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: who am i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: As far as our conversation is concerned, you are the user interacting with the NVIDIA Deep Learning Institute's (DLI) chat support."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: what's my name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: You haven't shared your name with me yet. We're still at the beginning of our conversation! Would you like to introduce yourself?"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: \n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia import ChatNVIDIA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from functools import partial\n",
    "\n",
    "## Define an NVIDIA-backed LLM\n",
    "llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\", base_url=\"http://llm_client:9000/v1\")\n",
    "\n",
    "## Define a structured prompt\n",
    "sys_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful assistant for NVIDIA Deep Learning Institute (DLI). \"\n",
    "     \"Assist users with their workshop-related queries using the provided context. \"\n",
    "     \"Do not reference the 'context' as 'context' explicitly.\"),\n",
    "    (\"user\", \"<context>\\n{context}</context>\"),\n",
    "    (\"ai\", \"Thank you. I will not restart the conversation and will abide by the context.\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "## Construct the processing pipeline\n",
    "chat_chain = sys_prompt | llm | StrOutputParser()\n",
    "\n",
    "## Initialize chatbot state\n",
    "state = {\n",
    "    \"messages\": [(\"ai\", \"Hello! I'm the NVIDIA DLI Chatbot! How can I help you?\")],\n",
    "    \"context\": \"\",  # Empty for now; will be updated later\n",
    "}\n",
    "\n",
    "## Wrap function to integrate AI response generation\n",
    "chat = partial(chat_with_chain, chain=chat_chain)\n",
    "\n",
    "## Start the chatbot with the AI pipeline\n",
    "chat(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db33c4-be56-49a8-984c-cb4a4192ec3d",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "### **Part 2:** Pulling In Some Context\n",
    "\n",
    "For this course, we will start by using a small dataset of workshop catalog from the GTC 2025 conference. This includes a real selection of workshops which were each proposed independently and vary in detail. This should be reminiscent of an organically-accumulated datapool... partially because it is one. The data can be found in [`gtc-data-2025.csv`](./gtc-data-2025.csv), so let's go ahead and load it in as a list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f05dd8-73a9-4044-9e36-81f4242c3ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health',\n",
       "  'description': \"This training lab explores the cutting-edge capabilities of NVIDIA's suite of AI tools — NVIDIA Inference Microservices (NIMs) and NVIDIA AI Blueprints — in transforming digital health solutions. Gain hands-on experience developing sophisticated AI-driven applications that can converse with multimodal healthcare data, enhance clinician-patient interactions, and extract valuable insights from healthcare video content. Explore NVIDIA-optimized large language models (LLMs), advanced techniques like retrieval augmented generation (RAG) and agentic LLM systems, as well as applications in speech AI and digital human technology. We'll emphasize the practical aspects of deploying these GPU-accelerated technologies and customizing them to specific digital health scenarios.\",\n",
       "  'instructors': 'Jin Li // Katie Link'},\n",
       " {'name': 'Advanced Medical AI Development with MONAI: From Interactive Annotation to Foundation Models',\n",
       "  'description': 'This hands-on training lab demonstrates how to build end-to-end medical AI workflows using the latest tools: MONAI Label, VISTA-3D, MAISI, and VILA-M3. Learn to combine AI-assisted annotation, interactive segmentation, synthetic data generation, and advanced visual-language understanding to create powerful medical imaging applications. Gain practical experience with these tools while understanding how they complement each other in real-world scenarios.',\n",
       "  'instructors': 'Ahmed Harouni'},\n",
       " {'name': 'Building Digital Twin Environments With OpenUSD, NVIDIA Isaac Sim, and ROS: A Hands-On Approach to Robotics Simulation',\n",
       "  'description': \"This lab focuses on creating a digital twin environment and simulating robots within it. Learn to assemble a virtual environment using 3D CAD data with OpenUSD, NVIDIA Omniverse, and USD Search NIM. Then explore NVIDIA Isaac Sim to add virtual robots to the scene and simulate their basic movements with ROS commands. The lab will emphasize data aggregation, environment creation, and initial robot simulation.\\n \\n By the end of this lab, you'll be able to create a detailed digital twin environment and simulate basic robot movements within it using the Robot Operating System (ROS). This lab is designed for developers interested in digital twin technology and robotics simulation in industrial settings.\",\n",
       "  'instructors': 'Ayush Ghosh // Steven Feng'},\n",
       " {'name': 'Build Your First AI Robotic Arm With OpenVLA and Isaac Sim',\n",
       "  'description': \"Physical AI is transforming many industries. Get a hands-on introduction to creating a simulated robotic arm using OpenVLA, a state-of-the-art, open-source vision-language-action (VLA) model, and NVIDIA Isaac Sim, a high-fidelity simulation platform for robotics. Learn how to set up and integrate these tools to simulate and control a robotic arm. We'll cover the basics of pre-trained VLA models and offer practical guidance on fine-tuning these models for specific tasks using LORA. Then, you'll use IsaacSim to simulate and control a simulated robotic arm. In the end, you'll have the foundation to build and adapt robotic applications in a simulated environment, paving the way for future exploration and development in robotics without the need for costly physical hardware. The workshop is structured like this:\\n \\n 1. Introduction to OpenVLA (20 mins)\\n 2. Lab training fine-tuning (30 mins)\\n 3. IsaacSim (20 min)\\n 4. Lab deploy OpenVLA to IsaacSim (30 mins)\",\n",
       "  'instructors': 'Abubakr Karali // Maycon da Silva Carvalho // Teresa Conceicao'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "## Load dataset\n",
    "filepath = \"gtc-data-2025.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "## Convert to JSON for structured processing\n",
    "raw_entries = json.loads(df.to_json(orient=\"records\"))\n",
    "\n",
    "## Display the first few records\n",
    "raw_entries[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef7a275-fdda-4cb1-9ffb-4f4c0e153f06",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We can quickly process them into a more natural format, and then try to concatenate them together to create a viable \"context string\" for our model. Automation to create context is quite common in real workflows to augment LLMs, so no reason not to do it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "418e8f53-63b8-42f3-a391-a18d407134f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Context Length (characters): 50559\n",
      "----------------------------------------\n",
      "The following workshops are slated to be presented at NVIDIA's GTC 2025 Conference:\n",
      "\n",
      "[Session 1]\n",
      "Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health\n",
      "Presenters: Jin Li // Katie Link\n",
      "Description: This training lab explores the cutting-edge capabilities of NVIDIA's suite of AI tools — NVIDIA Inference Microservices (NIMs) and NVIDIA AI Blueprints — in transforming digital health solutions. Gain hands-on experience developing sophisticated AI-driven applications that can converse with multimodal healthcare data, enhance clinician-patient interactions, and extract valuable insights from healthcare video content. Explore NVIDIA-optimized large language models (LLMs), advanced techniques like retrieval augmented generation (RAG) and agentic LLM systems, as well as applications in speech AI and digital human technology. We'll emphasize the practical aspects of deploying these GPU-accelerated technologies and customizing them to specific digital health scenarios.\n",
      "\n",
      "[Session 2]\n",
      "Advanced Medical AI Development with MONAI: From Interactive Annotation to Foundation Models\n",
      "Presenters: Ahmed Harouni\n",
      "Description: This hands-on training lab demonstrates how to build end-to-end medical AI workflows using the latest tools: MONAI Label, VISTA-3D, MAISI, and VILA-M3. Learn to combine AI-assisted annotation, interactive segmentation, synthetic data generation, and advanced visual-language understanding to create powerful medical imaging applications. Gain practical experience with these tools while understanding how they complement each other in real-world scenarios.\n",
      "\n",
      "[Session 3]\n",
      "Building Digital Twin Environments With OpenUSD, NVIDIA Isaac Sim, and ROS: A Hands-On Approach to Robotics Simulation\n",
      "Presenters: Ayush Ghosh // Steven Feng\n",
      "Description: This lab focuses on creating a digital twin environment and simulating robots within it. Learn to assemble a virtual environment using 3D CAD data with OpenUSD, NVIDIA Omniverse, and USD Search NIM. Then explore NVIDIA Isaac Sim to add\n"
     ]
    }
   ],
   "source": [
    "def stringify(entry, description_key='description'):\n",
    "    \"\"\"Formats workshop details into a human-readable string.\"\"\"\n",
    "    return (\n",
    "        f\"{entry.get('name')}\\n\"\n",
    "        f\"Presenters: {entry.get('instructors')}\\n\"\n",
    "        f\"Description: {entry.get(description_key)}\"\n",
    "    )\n",
    "\n",
    "## Convert dataset entries to structured text\n",
    "raw_blurbs = [\n",
    "    f\"[Session {i+1}]\\n{stringify(entry)}\" \n",
    "    for i, entry in enumerate(raw_entries)\n",
    "]\n",
    "\n",
    "## Construct full context string\n",
    "raw_context = \"The following workshops are slated to be presented at NVIDIA's GTC 2025 Conference:\\n\\n\"\n",
    "raw_context += \"\\n\\n\".join(raw_blurbs)\n",
    "\n",
    "## Display context statistics\n",
    "print(f\"Full Context Length (characters): {len(raw_context)}\")\n",
    "print(\"-\"*40)\n",
    "print(raw_context[:2000])  # Preview the first portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1e5172-768e-4d06-8aee-7e2c9d647783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: what's going on\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: It looks like you're referring to the NVIDIA Deep Learning Institute's GTC 2025 Conference, which appears to have a variety of workshops and sessions lined up. If you'd like, I can provide more information about specific sessions or help you navigate the schedule. What would you like to know?"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: sessions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: There are 67 sessions listed for the NVIDIA Deep Learning Institute's GTC 2025 Conference. I can provide more information about each session, such as the title, presenters, and description.\n",
      "\n",
      "If you'd like, I can also help you filter the sessions by category, such as 'Digital Health', 'Robotics and Simulation', 'Language Models', or others.\n",
      "\n",
      "Which category or type of session are you interested in?"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: Building Agentic AI Applications With Large Language Models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: Building Agentic AI Applications With Large Language Models is a fascinating area of research and development.\n",
      "\n",
      "It looks like you might be interested in Session 41, \"Structure From Chaos: Accelerate GraphRAG With cuGraph and NVIDIA NIM\", and Session 36, \"Build Visual AI Agents With RAG Using NVIDIA Morpheus, RIVA, and Metropolis\", which both involve building agentic AI applications with large language models.\n",
      "\n",
      "However, I think the most relevant session might be Session 41, \"Build Agentic AI Workflows for Enterprise Applications\", which specifically focuses on building agentic AI workflows for enterprise applications. The session description mentions that you'll learn to deploy an agentic AI workflow, create tools for an AI agent, and quickly augment existing workflows with new tools.\n",
      "\n",
      "Another session that seems related is Session 39, \"Learn to Build Agentic AI Workflows for Enterprise Applications\", which also deals with building agentic AI workflows.\n",
      "\n",
      "Would you like me to elaborate on any of these sessions or provide more information about building agentic AI applications?"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: specifically DCW51103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: DCW51103 is a specific session title. \n",
      "\n",
      "After looking it up, I found that it corresponds to Session 41: \"Structure From Chaos: Accelerate GraphRAG With cuGraph and NVIDIA NIM\".\n",
      "\n",
      "However, I also noticed that the session title is a bit misleading, as it seems to be focused on Accelerating GraphRAG with cuGraph and NVIDIA NIM, rather than specifically \"Building Agentic AI Applications With Large Language Models\".\n",
      "\n",
      "The session description does mention learning to integrate large language models (LLMs) with NVIDIA Inference Microservices (NIM) and cuGraph to create cutting-edge, graph-based AI solutions for handling complex, interconnected data.\n",
      "\n",
      "However, I'm not seeing any direct connection to agentic AI applications in the session description.\n",
      "\n",
      "If you could provide more information about what you're looking for in a session about building agentic AI applications with large language models, I may be able to help you better."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: \n"
     ]
    }
   ],
   "source": [
    "## Using your previous abstraction, pass the context into your prompt and see if it works:\n",
    "## Initialize chatbot state\n",
    "state = {\n",
    "    \"messages\": [(\"ai\", \"Hello! I'm the NVIDIA DLI Chatbot! How can I help you?\")],\n",
    "    \"context\": raw_context,  \n",
    "}\n",
    "try:\n",
    "    ## TODO: Perform the conversation with your long context (it's ok if it fails)\n",
    "    chat(state)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a3275-511f-402d-84be-cb12b5a8ae58",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<details><summary><b>Hint</b></summary>\n",
    "\n",
    "Recall that we just have a `chat` function which wraps a reusable chain. So we can just invoke it using `chat(state)` for some `state`. Then, we just need to figure out what should go in our prompt. To refresh your memory:\n",
    "\n",
    "```python\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful instructor assistant for NVIDIA Deep Learning Institute (DLI). \"\n",
    "     \"Assist users with their course-related queries using the provided context. \"\n",
    "     \"Do not reference the 'context' as 'context' explicitly.\"),\n",
    "    (\"user\", \"<context>\\n{context}</context>\"),\n",
    "    (\"ai\", \"Thank you. I will not restart the conversation and will abide by the context.\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "<details><summary><b>Solution</b></summary>\n",
    "\n",
    "Given that our prompt expects to take in a dictionary which includes a `context` (interpretable as strings) and `messages` (interpretable as a list of messages like `[(\"user\", \"Hello World\")]`), we can initiate our prompt with no message history and the `raw_context` as our context.\n",
    "\n",
    "```python\n",
    "state = {\"messages\": [], \"context\": raw_context,}\n",
    "try:\n",
    "    chat(state)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "This probably didn't work, and for good reason. The model is launched with a max context of `2^13 = 8192` tokens, and the current context is probably a bit too long. Let's verify it with a [tokenizer](https://huggingface.co/unsloth/Meta-Llama-3.1-8B-Instruct/blob/main/tokenizer.json) for the model in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbea4244-8242-48a5-b1cf-fcf27dde1290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Length of Context: 50559\n",
      "Token Length of Context: 10107\n",
      "The following workshops are slated to be presented at NVIDIA's GTC 2025 Conference:\n",
      "\n",
      "[Session 1]\n",
      "Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health\n",
      "Presenters: Jin Li // Katie Link\n",
      "Description: This training lab explores the cutting-edge capabilities of NVIDIA's suite of AI tools — NVIDIA Inference Microservices (NIMs) and NVIDIA AI Blueprints — in transforming digital health solutions. Gain hands-on experience developing sophisticated AI-driven applications that can converse with multimodal healthcare data, enhance clinician-patient interactions, and extract valuable insights from healthcare video content. Explore NVIDIA-optimized large language models (LLMs), advanced techniques like retrieval augmented generation (RAG) and agentic LLM systems, as well as applications in speech AI and digital human technology. We'll emphasize the practical aspects of deploying these GPU-accelerated technologies and customizing them to specific digital health scenarios.\n",
      "\n",
      "[Session 2]\n",
      "Advanced Medical AI Development with MONAI: From Interactive Annotation to Foundation Models\n",
      "Presenters: Ahmed Harouni\n",
      "Description: This hands-on training lab demonstrates how to build end-to-end medical AI workflows using the latest tools: MONAI Label, VISTA-3D, MAISI, and VILA-M3. Learn to combine AI-assisted annotation, interactive segmentation, synthetic data generation, and advanced visual-language understanding to create powerful medical imaging applications. Gain practical experience with these tools while understanding how they complement each other in real-world scenarios.\n",
      "\n",
      "[Session 3]\n",
      "Building Digital Twin Environments With OpenUSD, NVIDIA Isaac Sim, and ROS: A Hands-On Approach to Robotics Simulation\n",
      "Presenters: Ayush Ghosh // Steven Feng\n",
      "Description: This lab focuses on creating a digital twin environment and simulating robots within it. Learn to assemble a virtual environment using 3D CAD data with OpenUSD, NVIDIA Omniverse, and USD Search NIM. Then explore NVIDIA Isaac Sim to add\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "llama_tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"tokenizer.json\", clean_up_tokenization_spaces=True)\n",
    "\n",
    "def token_len(text):\n",
    "    \"\"\"Counts token length of given text.\"\"\"\n",
    "    return len(llama_tokenizer.encode(text=text))\n",
    "\n",
    "print(f\"String Length of Context: {len(raw_context)}\")\n",
    "print(f\"Token Length of Context: {token_len(raw_context)}\")\n",
    "\n",
    "## Preview context\n",
    "print(raw_context[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14702102-4fb0-46ef-9fcc-2e720a1a1c5d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**You may be thinking \"don't most models have much longer contexts,\" and you would be right with a few key caveats:**\n",
    "\n",
    "- Using an API service, you would still be paying for the tokens anyway, so maybe having a long static context isn't the best idea?\n",
    "- Even if your context length is supported, most models still experience some amount of quality degredation as your inputs get longer. Furthermore, more inputs = more opportunities for conflicting data and text structures.\n",
    "- For an arbitrary document or even a document pool, you are likely to find yourself stretching into max context more often than not. Even if a model is good for this dataset, will it still work well for a database?\n",
    "\n",
    "In our case, we are operating on a sample of course descriptions of various detail and quality, which adds up to a large pool of inconsistent entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d0eee7-d819-45fa-9776-8127f6611279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHORTEST ENTRIES:\n",
      "[Session 12]\n",
      "An Introduction to NVIDIA Cosmos for Physical AI\n",
      "Presenters: None\n",
      "Description: None \n",
      "\n",
      "[Session 27]\n",
      "CUTLASS Walkthrough\n",
      "Presenters: Vijay Thakkar\n",
      "Description: Join our walkthrough for everything new in CUTLASS such as Blackwell, Flash Attention 3, and Python Interface. We'll mix lecture portions with hands-on examples. \n",
      "\n",
      "[Session 50]\n",
      "Accelerating Clustering Algorithms to Achieve the Highest Performance\n",
      "Presenters: Allison Ding\n",
      "Description: Clustering is commonly applied across industries for applications such as recommendation systems and fraud detection. In this lab, through examples, we will discuss techniques to accelerate common clustering algorithms and tips/tricks to derive the highest performance. \n",
      "\n",
      "[Session 4]\n",
      "Build Your First AI Robotic Arm With OpenVLA and Isaac Sim\n",
      "Presenters: Abubakr Karali // Maycon da Silva Carvalho // Teresa Conceicao\n",
      "Description: Physical AI is transforming many industries. Get a hands-on introduction to creating a simulated robotic arm using OpenVLA, a state-of-the-art, open-source vision-language-action (VLA) model, and NVIDIA Isaac Sim, a high-fidelity simulation platform for robotics. Learn how to set up and integrate these tools to simulate and control a robotic arm. We'll cover the basics of pre-trained VLA models and offer practical guidance on fine-tuning these models for specific tasks using LORA. Then, you'll use IsaacSim to simulate and control a simulated robotic arm. In the end, you'll have the foundation to build and adapt robotic applications in a simulated environment, paving the way for future exploration and development in robotics without the need for costly physical hardware. The workshop is structured like this:\n",
      " \n",
      " 1. Introduction to OpenVLA (20 mins)\n",
      " 2. Lab training fine-tuning (30 mins)\n",
      " 3. IsaacSim (20 min)\n",
      " 4. Lab deploy OpenVLA to IsaacSim (30 mins) \n",
      "\n",
      "[Session 35]\n",
      "“I See Dead Pipelines...Without CI/CD:\" The Gen AI Easy Button for Fine-Tuning, Evaluation, and Inference With NVIDIA NIMs and Nemo Microservices\n",
      "Presenters: Anshul Jindal // Dmitry Mironov // Martin Piercy\n",
      "Description: \"Dead pipelines\" — abandoned scripts that once ran parts of a workflow — plague LLM development, causing errors, delays, and wasted resources. Learn how to automate the entire LLM life cycle using CI/CD pipelines, Kubernetes, NVIDIA NIMs, and Nemo Microservices in a cloud-agnostic approach. Discover how to streamline development, fine-tuning, evaluation, and deployment of LLMs, ensuring seamless integration, validation, and deployment of updates.\n",
      " \n",
      " In this hands-on course, you'll:\n",
      " \n",
      " • Design and build a cloud-agnostic LLMOps CI/CD pipeline on Kubernetes for scalable and flexible Gen AI app deployment\n",
      " • Utilize Argo CD for declarative continuous delivery and Argo Workflows for managing complex LLM workflows\n",
      " • Leverage NVIDIA NIMs and NeMo Microservices in the end-to-end LLMOps pipeline\n",
      " • Learn how to improve development cycles, accuracy, and reliability with automated fine-tuning and continuous evaluation \n",
      "\n",
      "[Session 21]\n",
      "Build Next-Gen Agents With Large Vision Language Models\n",
      "Presenters: Abubakr Karali // Debraj Sinha // Sammy Ochoa\n",
      "Description: Vision-language models (VLM) are taking computer vision by storm, offering scalability and robust zero-shot solution for countless industries. However, there are many challenges along the way to deploying VLMs. In this workshop, we'll demystify these challenges. You'll learn what VLMs are, and we'll show you how to choose the best model, how to train and fine-tune on a small dataset, and how to deploy and use VLMs scene understanding with NVIDIA Nemo. Then we'll show different workflows for VLM deployment, with NIMs and VIA including grounding the models for more accurate results. \n",
      " \n",
      " The workshop will be structured as follows:\n",
      " 1) Introduction to VLMs (40 mins)\n",
      " a. Families of VLMs \n",
      " b. Choice of the right VLMs\n",
      " c. Training/evaluation\n",
      " d. Fine-tuning\n",
      " e. Where to start\n",
      " 2) Introduction NIMs (10 mins)\n",
      " 3) Hands-on experience with VLM models through NIMs (20 mins)\n",
      " 4) Introduction to VIA (10 mins)\n",
      " 5) Deploy VLM with VIA reference application (20 mins) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sorted_raw_blurbs = sorted(raw_blurbs, key=token_len)\n",
    "\n",
    "def plot_token_len(entries, color=\"green\", alpha=1, len_fn=token_len):\n",
    "    \"\"\"Plots token lengths of all entries.\"\"\"\n",
    "    plt.bar(x=range(len(entries)), height=[len_fn(v) for v in entries], width=1.0, color=color, alpha=alpha)\n",
    "\n",
    "plot_token_len(sorted_raw_blurbs, color=\"green\")\n",
    "plt.xlabel(\"Entry Sample Number\")\n",
    "plt.ylabel(\"Token Length\")\n",
    "plt.show() \n",
    "\n",
    "print(\"SHORTEST ENTRIES:\")\n",
    "sample_blurbs = sorted_raw_blurbs[:3] + sorted_raw_blurbs[-3:]\n",
    "\n",
    "for entry in sample_blurbs:\n",
    "    print(entry, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a997a46-37b3-4461-ae0f-e35b2ebdad6e",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "### **Part 3:** Summarizing Our Long Context\n",
    "\n",
    "Maybe we can convert each of these entries into something shorter and more uniform? Maybe as a preprocessing step, we can just process all of these entries into a more consistent form. Not only will this help our model reason about the full context, but we'll also be able to leverage the entries' uniform nature to improve the consistency of our prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0475ac8a-536c-4ed6-b4a6-8f2a2a91cbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Summary) This hands-on training lab demonstrates how to build end-to-end medical AI workflows using MONAI tools such as MONAI Label, VISTA-3D, MAISI, and VILA-M3. The lab covers combining AI-assisted annotation, segmentation, synthetic data generation, and visual-language understanding for powerful medical imaging applications.\n",
      "CPU times: user 8.87 ms, sys: 0 ns, total: 8.87 ms\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## TODO: Create a symmary system message to instruct the LLM.\n",
    "## Reuse the chat_chain as-it-was, remembering that it expects \"messages\" and \"context\"\n",
    "summary_msg = (\n",
    "    \"Summarize the presentation description down to only a few important sentences.\"\n",
    "    \" Start with '(Summary) '\"\n",
    "    ## Feel free to customize\n",
    ")\n",
    "\n",
    "def summarize(context_str, summary_msg=summary_msg):\n",
    "    return chat_chain.invoke({\n",
    "    \"messages\": [(\"user\", summary_msg)],\n",
    "    \"context\": context_str\n",
    "})\n",
    "\n",
    "print(summarize(stringify(raw_entries[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497fece0-31e4-4dde-8059-1b196c376093",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<details><summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "return chat_chain.invoke({\n",
    "    \"messages\": [(\"user\", summary_msg)],\n",
    "    \"context\": context_str\n",
    "})\n",
    "```\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "It's natural language and not required to be well-formatted, but we can sufficiently prompt-engineer it for a simple text-to-text transformation function. We can also use the LangChain batching primitives to greatly simplify our concurrency management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15264663-4e21-479f-9d16-3a7172975165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bd2132f45a43689dfd24c3d0754f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 369 ms, sys: 81.1 ms, total: 450 ms\n",
      "Wall time: 5.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from tqdm.auto import tqdm\n",
    "import threading\n",
    "\n",
    "batch_inputs = [stringify(entry_dict) for entry_dict in raw_entries]\n",
    "\n",
    "## Simple version of a batched process. No progress bar\n",
    "# summaries = RunnableLambda(summarize).batch(batch_inputs, config={\"max_concurrency\": 20})\n",
    "\n",
    "## Modified version which also has progress bars! Marginally-slower, same backbone\n",
    "def batch_process(fn, inputs, max_concurrency=20):\n",
    "    lock = threading.Lock()\n",
    "    pbar = tqdm(total=len(inputs))\n",
    "    def process_doc(value):\n",
    "        try:\n",
    "            output = fn(value)\n",
    "        except Exception as e: \n",
    "            print(f\"Exception in thread: {e}\")\n",
    "        with lock:\n",
    "            pbar.update(1)\n",
    "        return output\n",
    "    try:\n",
    "        lc_runnable = fn if hasattr(fn, \"batch\") else RunnableLambda(process_doc)\n",
    "        return lc_runnable.batch(inputs, config={\"max_concurrency\": max_concurrency})\n",
    "    finally:\n",
    "        pbar.close()\n",
    "\n",
    "summaries = batch_process(summarize, batch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06df66-ec7d-4892-94c7-eb97df4558f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68b853-1c83-4ad6-98cf-22e970211229",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Now that we have this new summary, we can see what happens when we use this synthetic description instead of our original ones, and consider how our context length is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f79fb0-1b82-4ae8-b6c4-454d98d0be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health\n",
      "Presenters: Jin Li // Katie Link\n",
      "Description: This training lab explores the capabilities of NVIDIA's AI tools in transforming digital health solutions. We'll have hands-on experience developing AI-driven applications and exploring NVIDIA-optimized large language models, advanced techniques like retrieval augmented generation (RAG), and applications in speech AI and digital human technology. Emphasis will be on practical aspects of deploying and customizing these GPU-accelerated technologies for digital health scenarios.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health',\n",
       " 'description': \"This training lab explores the cutting-edge capabilities of NVIDIA's suite of AI tools — NVIDIA Inference Microservices (NIMs) and NVIDIA AI Blueprints — in transforming digital health solutions. Gain hands-on experience developing sophisticated AI-driven applications that can converse with multimodal healthcare data, enhance clinician-patient interactions, and extract valuable insights from healthcare video content. Explore NVIDIA-optimized large language models (LLMs), advanced techniques like retrieval augmented generation (RAG) and agentic LLM systems, as well as applications in speech AI and digital human technology. We'll emphasize the practical aspects of deploying these GPU-accelerated technologies and customizing them to specific digital health scenarios.\",\n",
       " 'instructors': 'Jin Li // Katie Link',\n",
       " 'summary': \"This training lab explores the capabilities of NVIDIA's AI tools in transforming digital health solutions. We'll have hands-on experience developing AI-driven applications and exploring NVIDIA-optimized large language models, advanced techniques like retrieval augmented generation (RAG), and applications in speech AI and digital human technology. Emphasis will be on practical aspects of deploying and customizing these GPU-accelerated technologies for digital health scenarios.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "## Defined Earlier\n",
    "\n",
    "# def stringify(entry, description_key='description'):\n",
    "#     return (\n",
    "#         f\"{entry.get('name')}\"\n",
    "#         f\"\\nPresentors: {entry.get('instructors')}\"\n",
    "#         f\"\\nDescription: {entry.get(description_key)}\"\n",
    "#     )\n",
    "\n",
    "## Defined Earlier\n",
    "#############################################################################\n",
    "\n",
    "for summary, pres_entry in zip(summaries, raw_entries):\n",
    "    words = summary.split()\n",
    "    ## Remove \"summary\" or \"(summary)\" from text\n",
    "    if \"summary\" in words[0].lower():\n",
    "        words = words[1:]\n",
    "    pres_entry[\"summary\"] = \" \".join(words)\n",
    "\n",
    "print(stringify(raw_entries[0], \"summary\"))\n",
    "raw_entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d0ac496-bc50-4569-8cf0-7c815da7e597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:\n",
      "An Introduction to NVIDIA Cosmos for Physical AI\n",
      "Presentors: None\n",
      "Description: None\n",
      "Summary: (No context provided earlier) However, I'm assuming it's about the workshop 'An Introduction to NVIDIA Cosmos for Physical AI'. (However, since there's no actual context, I'll skip summarizing and do a different task. If you provide the actual presentation description, I would be happy to assist!) Would you like to provide the actual presentation description or ask a question about the workshop?\n",
      "\n",
      "\n",
      "CUTLASS Walkthrough\n",
      "Presentors: Vijay Thakkar\n",
      "Description: Join our walkthrough for everything new in CUTLASS such as Blackwell, Flash Attention 3, and Python Interface. We'll mix lecture portions with hands-on examples.\n",
      "Summary: Join a walkthrough of the latest advancements in CUTLASS, including new features and tools, with lecture and hands-on example sections. The presentation will cover cutting-edge topics such as Blackwell, Flash Attention 3, and a Python interface.\n",
      "\n",
      "\n",
      "Accelerating Clustering Algorithms to Achieve the Highest Performance\n",
      "Presentors: Allison Ding\n",
      "Description: Clustering is commonly applied across industries for applications such as recommendation systems and fraud detection. In this lab, through examples, we will discuss techniques to accelerate common clustering algorithms and tips/tricks to derive the highest performance.\n",
      "Summary: Clustering is a widely used technique in industry applications like recommendation systems and fraud detection. In this workshop, we will accelerate common clustering algorithms and share tips for achieving the highest performance.\n",
      "\n",
      "\n",
      "“I See Dead Pipelines...Without CI/CD:\" The Gen AI Easy Button for Fine-Tuning, Evaluation, and Inference With NVIDIA NIMs and Nemo Microservices\n",
      "Presentors: Anshul Jindal // Dmitry Mironov // Martin Piercy\n",
      "Description: \"Dead pipelines\" — abandoned scripts that once ran parts of a workflow — plague LLM development, causing errors, delays, and wasted resources. Learn how to automate the entire LLM life cycle using CI/CD pipelines, Kubernetes, NVIDIA NIMs, and Nemo Microservices in a cloud-agnostic approach. Discover how to streamline development, fine-tuning, evaluation, and deployment of LLMs, ensuring seamless integration, validation, and deployment of updates.\n",
      " \n",
      " In this hands-on course, you'll:\n",
      " \n",
      " • Design and build a cloud-agnostic LLMOps CI/CD pipeline on Kubernetes for scalable and flexible Gen AI app deployment\n",
      " • Utilize Argo CD for declarative continuous delivery and Argo Workflows for managing complex LLM workflows\n",
      " • Leverage NVIDIA NIMs and NeMo Microservices in the end-to-end LLMOps pipeline\n",
      " • Learn how to improve development cycles, accuracy, and reliability with automated fine-tuning and continuous evaluation\n",
      "Summary: This presentation aims to solve the issue of abandoned and broken scripts (\"dead pipelines\") in LLM (Large Language Model) development. It will demonstrate how to automate the entire LLM life cycle using CI/CD pipelines, NVIDIA NIMs, and Nemo Microservices on a cloud-agnostic approach, allowing for seamless integration, validation, and deployment of updates.\n",
      "\n",
      "\n",
      "Build Your First AI Robotic Arm With OpenVLA and Isaac Sim\n",
      "Presentors: Abubakr Karali // Maycon da Silva Carvalho // Teresa Conceicao\n",
      "Description: Physical AI is transforming many industries. Get a hands-on introduction to creating a simulated robotic arm using OpenVLA, a state-of-the-art, open-source vision-language-action (VLA) model, and NVIDIA Isaac Sim, a high-fidelity simulation platform for robotics. Learn how to set up and integrate these tools to simulate and control a robotic arm. We'll cover the basics of pre-trained VLA models and offer practical guidance on fine-tuning these models for specific tasks using LORA. Then, you'll use IsaacSim to simulate and control a simulated robotic arm. In the end, you'll have the foundation to build and adapt robotic applications in a simulated environment, paving the way for future exploration and development in robotics without the need for costly physical hardware. The workshop is structured like this:\n",
      " \n",
      " 1. Introduction to OpenVLA (20 mins)\n",
      " 2. Lab training fine-tuning (30 mins)\n",
      " 3. IsaacSim (20 min)\n",
      " 4. Lab deploy OpenVLA to IsaacSim (30 mins)\n",
      "Summary: This workshop introduces creating a simulated robotic arm using OpenVLA and NVIDIA Isaac Sim. Attendees will learn the basics of pre-trained VLA models, fine-tuning using LORA, and then use IsaacSim to simulate and control a robotic arm. This hands-on experience will provide the foundation to build and adapt robotic applications in a simulated environment.\n",
      "\n",
      "\n",
      "Build Next-Gen Agents With Large Vision Language Models\n",
      "Presentors: Abubakr Karali // Debraj Sinha // Sammy Ochoa\n",
      "Description: Vision-language models (VLM) are taking computer vision by storm, offering scalability and robust zero-shot solution for countless industries. However, there are many challenges along the way to deploying VLMs. In this workshop, we'll demystify these challenges. You'll learn what VLMs are, and we'll show you how to choose the best model, how to train and fine-tune on a small dataset, and how to deploy and use VLMs scene understanding with NVIDIA Nemo. Then we'll show different workflows for VLM deployment, with NIMs and VIA including grounding the models for more accurate results. \n",
      " \n",
      " The workshop will be structured as follows:\n",
      " 1) Introduction to VLMs (40 mins)\n",
      " a. Families of VLMs \n",
      " b. Choice of the right VLMs\n",
      " c. Training/evaluation\n",
      " d. Fine-tuning\n",
      " e. Where to start\n",
      " 2) Introduction NIMs (10 mins)\n",
      " 3) Hands-on experience with VLM models through NIMs (20 mins)\n",
      " 4) Introduction to VIA (10 mins)\n",
      " 5) Deploy VLM with VIA reference application (20 mins)\n",
      "Summary: This workshop will demystify the challenges of deploying vision-language models (VLMs), covering how to choose the best model, train and fine-tune on small datasets, and deploy VLMs for scene understanding using NVIDIA Nemo. The workshop will include hands-on experience with NVidia's NIMs and VIA tools.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "contexts_with_summaries = [stringify(entry, \"summary\") for entry in raw_entries]\n",
    "contexts_with_descripts = [stringify(entry) for entry in raw_entries]\n",
    "\n",
    "def plot_token_len(entries, color=\"green\", alpha=1, len_fn=token_len):\n",
    "    plt.bar(x=range(len(entries)), height=[len_fn(v) for v in entries], width=1.0, color=color, alpha=alpha)    \n",
    "\n",
    "## Create arrays of the token lengths\n",
    "sorted_summs = [v for _,v in sorted(zip((token_len(x) for x in contexts_with_summaries), contexts_with_summaries))]\n",
    "sorted_origs = [v for _,v in sorted(zip((token_len(x) for x in contexts_with_descripts), contexts_with_descripts))]\n",
    "aligned_summs = [v for _,v in sorted(zip((token_len(x) for x in contexts_with_descripts), contexts_with_summaries))]\n",
    "plot_token_len(sorted_origs, alpha=0.6, color=\"green\")\n",
    "plot_token_len(sorted_summs, alpha=0.6, color=\"grey\")\n",
    "## Lightgreen bars represent the new context length for their respective original green bars\n",
    "plot_token_len(aligned_summs, alpha=0.6, color=\"lightgreen\")\n",
    "plt.xlabel(\"Entry Sample\")\n",
    "plt.ylabel(\"Token Length\")\n",
    "plt.show() \n",
    "\n",
    "print(\"Samples:\")\n",
    "sorted_raw_entries = sorted(raw_entries, key=(lambda v: token_len(str(v.get(\"description\")))))\n",
    "for entry in sorted_raw_entries[:3] + sorted_raw_entries[-3:]:\n",
    "    print(\n",
    "        f\"{entry.get('name')}\"\n",
    "        f\"\\nPresentors: {entry.get('instructors')}\"\n",
    "        f\"\\nDescription: {entry.get('description')}\"\n",
    "        f\"\\nSummary: {entry.get('summary')}\\n\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5978a60-8458-4a65-aa42-d6dd7d2e5e40",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Sounds like a promising direction! Let's implement it in practice and apply this change over all of our entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c094aa2f-3865-4485-bdcd-9ed2bcdf68d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Context Length: 31108\n",
      "New Context Tokens: 6146\n",
      "The following workshops are slated to be presented at NVIDIA's GTC 2025 Conference:\n",
      "\n",
      "Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health\n",
      "Presenters: Jin Li // Katie Link\n",
      "Description: This training lab explores the capabilities of NVIDIA's AI tools in transforming digital health solutions. We'll have hands-on experience developing AI-driven applications and exploring NVIDIA-optimized large language models, advanced techniques like retrieval augmented generation (RAG), and applications in speech AI and digital human technology. Emphasis will be on practical aspects of deploying and customizing these GPU-accelerated technologies for digital health scenarios.\n",
      "\n",
      "Advanced Medical AI Development with MONAI: From Interactive Annotation to Foundation Models\n",
      "Presenters: Ahmed Harouni\n",
      "Description: This hands-on training lab demonstrates how to build end-to-end medical AI workflows using MONAI tools such as MONAI Label, VISTA-3D, MAISI, and VILA-M3. The lab covers AI-assisted annotation, interactive segmentation, synthetic data generation, and advanced visual-language understanding for creating powerful medical imaging applications.\n",
      "\n",
      "Building Digital Twin Environments With OpenUSD, NVIDIA Isaac Sim, and ROS: A Hands-On Approach to Robotics Simulation\n",
      "Presenters: Ayush Ghosh // Steven Feng\n",
      "Description: This lab focuses on creating a digital twin environment using OpenUSD, NVIDIA Omniverse, and USD Search NIM, and simulating robots within it using NVIDIA Isaac Sim and ROS. By the end of this lab, you'll be able to create a detailed digital twin environment and simulate basic robot movements within it. This lab is designed for developers interested in digital twin technology and robotics simulation in industrial settings.\n",
      "\n",
      "Build Your First AI Robotic Arm With OpenVLA and Isaac Sim\n",
      "Presenters: Abubakr Karali // Maycon da Silva Carvalho // Teresa Conceicao\n",
      "Description: This workshop introduces creating a simulated robotic arm using OpenVLA and NVIDIA Isaac Sim. Attendees wil\n"
     ]
    }
   ],
   "source": [
    "## Construct full context string\n",
    "new_context = \"The following workshops are slated to be presented at NVIDIA's GTC 2025 Conference:\\n\\n\"\n",
    "new_context += \"\\n\\n\".join(contexts_with_summaries)\n",
    "print(\"New Context Length:\", len(new_context))\n",
    "print(f\"New Context Tokens: {token_len(new_context)}\")\n",
    "\n",
    "## Preview context\n",
    "print(new_context[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaaeaef-cb92-44ae-8016-8b3b84b9f890",
   "metadata": {},
   "source": [
    "And all of a sudden, we're below our input size threshold! Time to just swap out our context and test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a16e8c76-d2ad-4c08-a516-e16b336a6390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: list 3 sessions \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: Here are 3 sessions:\n",
      "\n",
      "1. **Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health**: This training lab explores the capabilities of NVIDIA's AI tools in transforming digital health solutions.\n",
      "2. **Building Digital Twin Environments With OpenUSD, NVIDIA Isaac Sim, and ROS: A Hands-On Approach to Robotics Simulation**: This lab focuses on creating a digital twin environment using OpenUSD, NVIDIA Omniverse, and USD Search NIM, and simulating robots within it using NVIDIA Isaac Sim and ROS.\n",
      "3. **Streamline Drug Discovery With NVIDIA BioNeMo NIMs and Blueprints**: The presentation will show how NVIDIA BioNeMo can improve the drug discovery process by using large biochemical datasets and generative AI."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: find session Building Agentic AI Applications With Large Language Models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: I couldn't find a session titled \"Building Agentic AI Applications With Large Language Models\" in the provided list. However, I did find a workshop titled \"Learn to Build Agentic AI Workflows for Enterprise Applications\" that seems to be related to building agentic AI applications. \n",
      "\n",
      "If that's not the one you were looking for, please let me know if I can help you find another session."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: \n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "## Defined Earlier. Feel free to play around with this\n",
    "\n",
    "## Define an NVIDIA-backed LLM\n",
    "llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\", base_url=\"http://llm_client:9000/v1\")\n",
    "\n",
    "## Define a structured prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful instructor assistant for NVIDIA Deep Learning Institute (DLI). \"\n",
    "     \"Assist users with their course-related queries using the provided context. \"\n",
    "     \"Do not reference the 'context' as 'context' explicitly.\"),\n",
    "    (\"user\", \"<context>\\n{context}</context>\"),\n",
    "    (\"ai\", \"Thank you. I will not restart the conversation and will abide by the context.\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "## Construct the processing pipeline\n",
    "chat_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "## Initialize chatbot state\n",
    "state = {\n",
    "    \"messages\": [(\"ai\", \"Hello! I'm the NVIDIA DLI Chatbot! How can I help you?\")],\n",
    "    \"context\": \"\",  # Empty for now; will be updated later\n",
    "}\n",
    "\n",
    "## Wrap function to integrate AI response generation\n",
    "chat = partial(chat_with_chain, chain=chat_chain)\n",
    "\n",
    "## Defined Earlier\n",
    "#############################################################################\n",
    "\n",
    "state = {\n",
    "    \"messages\": [],\n",
    "    \"context\": new_context,\n",
    "}\n",
    "\n",
    "try:  ## HINT: Consider putting your call logic in the try-catch\n",
    "    chat(state)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "400c2d22-53b2-4d30-8c57-6ccbd156f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consider saving the material as well, since it will be useful for later\n",
    "## For those who may take this course over multiple sessions, a version is provided.\n",
    "with open(\"simple_long_context.txt\", \"w\") as f:\n",
    "    f.write(new_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5f6ba-f953-4cac-8ef9-fc63788fcd5e",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "### **Part 4:** Reflecting On This Exercise\n",
    "\n",
    "This exercise was pretty easy, and did actually lead to an interesting system in some sense. \n",
    "- On a superficial level, all we did was take an overlong context and convert it down to a not-too-overlong context.\n",
    "- Using other terms, we \"canonicalized\" the elements in the global environment into a form that help make up a reasonable \"canonical context\" to our primary LLM.\n",
    "- Pessimistically, we have created a very short-term solution to our limited-context-space multi-turn problem by making the context *a little shorter* than our maximum input length.\n",
    "- Optimistically, we now have a reusable context which can help to keep our entire context within our model's input domain for most single-turn problems (including those that may complement a multi-turn solution).\n",
    "\n",
    "We will continue to use the results of this exercise throughout the coming notebooks, so hopefully the utility of this simple process becomes apparent as we go along!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59451af0-2bb8-430f-9b82-d76793421534",
   "metadata": {},
   "source": [
    "<br>\n",
    "<a href=\"https://www.nvidia.com/en-us/training/\">\n",
    "    <div style=\"width: 55%; background-color: white; margin-top: 50px;\">\n",
    "    <img src=\"https://dli-lms.s3.amazonaws.com/assets/general/nvidia-logo.png\"\n",
    "         width=\"400\"\n",
    "         height=\"186\"\n",
    "         style=\"margin: 0px -25px -5px; width: 300px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
