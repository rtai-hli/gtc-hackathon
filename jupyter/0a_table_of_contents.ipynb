{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b5289a-4240-422f-a0d4-1eb9adf26584",
   "metadata": {},
   "source": [
    "<br>\n",
    "<a href=\"https://www.nvidia.com/en-us/training/\">\n",
    "    <div style=\"width: 55%; background-color: white; margin-top: 50px;\">\n",
    "    <img src=\"https://dli-lms.s3.amazonaws.com/assets/general/nvidia-logo.png\"\n",
    "         width=\"400\"\n",
    "         height=\"186\"\n",
    "         style=\"margin: 0px -25px -5px; width: 300px\"/>\n",
    "</a>\n",
    "<h1 style=\"line-height: 1.4;\"><font color=\"#76b900\"><b>Building Agentic AI Applications with LLMs</b></h1>\n",
    "<h2><b>Table of Contents</b></h2>\n",
    "<br>\n",
    "\n",
    "### **Welcome to the course!** \n",
    "\n",
    "This course explores how to build agentic AI applications using large language models. You'll learn to create systems that can reason, use tools, and interact with their environment through hands-on exercises with **LangChain**, **LangGraph**, and **CrewAI**.\n",
    "\n",
    "**Throughout this course, you'll have access to several running services that power your development environment:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac783712",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"services.html\" width=\"100%\" height=\"600px\" style=\"border:1px solid #ccc; border-radius:4px;\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae30fa",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## <font color=\"#76b900\">**Course Structure**</font>\n",
    "\n",
    "The course is organized into the following sections:\n",
    "\n",
    "##### <font color=\"#76b900\">**Section 1: Making Simple Agents**</font>\n",
    "- **1a_basic_chat.ipynb** - Build your first chatbot and multi-agent system\n",
    "- **1e_dataset_chat.ipynb** - Create a chatbot that interacts with datasets\n",
    "- **1t_crewai.ipynb** - Explore the CrewAI framework for persona-based agents\n",
    "\n",
    "##### <font color=\"#76b900\">**Section 2: Structuring Thoughts and Outputs**</font>\n",
    "- **2a_structured_thought.ipynb** - Learn to structure LLM reasoning and outputs\n",
    "- **2e_metadata_gen.ipynb** - Generate structured metadata and long-form documents\n",
    "- **2t_tools.ipynb** - Build tooling-enabled LLM systems\n",
    "\n",
    "##### <font color=\"#76b900\">**Section 3: Using LangGraph**</font>\n",
    "- **3a_langgraph.ipynb** - Master LangGraph for agentic workflows\n",
    "- **3e_custom_persona.ipynb** - Implement custom persona systems with routing\n",
    "\n",
    "##### <font color=\"#76b900\">**Section 4: Assessment**</font>\n",
    "- **4a_retriever.ipynb** - Build a basic retrieval-augmented system (warm-up)\n",
    "- **4e_researcher.ipynb** - Create a researching agent (final assessment)\n",
    "\n",
    "<hr><br>\n",
    "\n",
    "## <font color=\"#76b900\">**Quick Start: Testing Your Environment**</font>\n",
    "\n",
    "Let's verify that all services are running correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37534a1-1ad3-4d4c-a358-6241d9387205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking running services...\n",
      "\n",
      "LLM Client           Running\n",
      "Docker Router        Running\n",
      "Jaeger (Tracing)     Running\n",
      "DDG Cache            Running\n",
      "LangGraph Viz        Running\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "print(\"üîç Checking running services...\\n\")\n",
    "\n",
    "services = {\n",
    "    \"LLM Client\": \"http://llm_client:9000/v1/models\",\n",
    "    \"Docker Router\": \"http://docker_router:8070/health\",\n",
    "    \"Jaeger (Tracing)\": \"http://jaeger:16686\",\n",
    "    \"DDG Cache\": \"http://ddg-cache:7860\",\n",
    "    \"LangGraph Viz\": \"http://lg_viz:3002\",\n",
    "}\n",
    "\n",
    "for name, url in services.items():\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        status = \"Running\" if response.status_code == 200 else f\"Status {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        status = f\"Not accessible\"\n",
    "    print(f\"{name:20} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52374b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing the LLM...\n",
      "\n",
      "Hello, how are you today?\n",
      "Goodbye, it was nice chatting with you!"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting the LLM...\\n\")\n",
    "\n",
    "from langchain_nvidia import ChatNVIDIA\n",
    "\n",
    "llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\", base_url=\"http://llm_client:9000/v1\")\n",
    "prompt = \"Say hello in one sentence!\"\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)\n",
    "\n",
    "for token in llm.stream([(\"human\", prompt), (\"ai\", response.content), (\"user\", \"Now say goodbye!\")]):\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53240e95",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### **Additional Resources**\n",
    "\n",
    "- **Observability**: Visit the Jaeger UI to trace requests through your system\n",
    "- **Logs**: Check Dozzle for real-time log streaming\n",
    "- **Database**: Explore cached data in DbGate\n",
    "- **LangGraph Visualization**: View execution graphs at LangGraph Viz\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Ready to Start?**\n",
    "\n",
    "Begin with **1a_basic_chat.ipynb** to build your first agent, or explore any section that interests you. All notebooks are self-contained with clear learning objectives.\n",
    "\n",
    "<center><a href=\"https://www.nvidia.com/dli\"> <img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" alt=\"Header\" style=\"width: 400px;\"/> </a></center>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
