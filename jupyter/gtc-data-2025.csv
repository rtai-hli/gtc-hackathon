name,description,instructors
Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health,"This training lab explores the cutting-edge capabilities of NVIDIA's suite of AI tools — NVIDIA Inference Microservices (NIMs) and NVIDIA AI Blueprints — in transforming digital health solutions. Gain hands-on experience developing sophisticated AI-driven applications that can converse with multimodal healthcare data, enhance clinician-patient interactions, and extract valuable insights from healthcare video content. Explore NVIDIA-optimized large language models (LLMs), advanced techniques like retrieval augmented generation (RAG) and agentic LLM systems, as well as applications in speech AI and digital human technology. We'll emphasize the practical aspects of deploying these GPU-accelerated technologies and customizing them to specific digital health scenarios.",Jin Li // Katie Link
Advanced Medical AI Development with MONAI: From Interactive Annotation to Foundation Models,"This hands-on training lab demonstrates how to build end-to-end medical AI workflows using the latest tools: MONAI Label, VISTA-3D, MAISI, and VILA-M3. Learn to combine AI-assisted annotation, interactive segmentation, synthetic data generation, and advanced visual-language understanding to create powerful medical imaging applications. Gain practical experience with these tools while understanding how they complement each other in real-world scenarios.",Ahmed Harouni
"Building Digital Twin Environments With OpenUSD, NVIDIA Isaac Sim, and ROS: A Hands-On Approach to Robotics Simulation","This lab focuses on creating a digital twin environment and simulating robots within it. Learn to assemble a virtual environment using 3D CAD data with OpenUSD, NVIDIA Omniverse, and USD Search NIM. Then explore NVIDIA Isaac Sim to add virtual robots to the scene and simulate their basic movements with ROS commands. The lab will emphasize data aggregation, environment creation, and initial robot simulation.
 
 By the end of this lab, you'll be able to create a detailed digital twin environment and simulate basic robot movements within it using the Robot Operating System (ROS). This lab is designed for developers interested in digital twin technology and robotics simulation in industrial settings.",Ayush Ghosh // Steven Feng
Build Your First AI Robotic Arm With OpenVLA and Isaac Sim,"Physical AI is transforming many industries. Get a hands-on introduction to creating a simulated robotic arm using OpenVLA, a state-of-the-art, open-source vision-language-action (VLA) model, and NVIDIA Isaac Sim, a high-fidelity simulation platform for robotics. Learn how to set up and integrate these tools to simulate and control a robotic arm. We'll cover the basics of pre-trained VLA models and offer practical guidance on fine-tuning these models for specific tasks using LORA. Then, you'll use IsaacSim to simulate and control a simulated robotic arm. In the end, you'll have the foundation to build and adapt robotic applications in a simulated environment, paving the way for future exploration and development in robotics without the need for costly physical hardware. The workshop is structured like this:
 
 1. Introduction to OpenVLA (20 mins)
 2. Lab training fine-tuning (30 mins)
 3. IsaacSim (20 min)
 4. Lab deploy OpenVLA to IsaacSim (30 mins)",Abubakr Karali // Maycon da Silva Carvalho // Teresa Conceicao
"Advanced Robot Learning With Digital Twins: Simulation, Task Generation, and Imitation Learning With NVIDIA Isaac Sim and Isaac Lab","This advanced session focuses on robot learning and task generation in the digital twin environment. Explore the full cycle of robot learning: data capture, simulation, motion generation, environment or task generation, and imitation learning of policies. You'll use NVIDIA Isaac Sim and Isaac Lab to train simulated robots for complex tasks.
 
 By the end of this lab, you'll be able to implement advanced robot learning techniques, generate complex tasks, and train AI-powered robots in a virtual environment, preparing them for deployment in real-world scenarios. This lab is ideal for developers with a foundation in robotics simulation who want to delve deeper into AI-powered robotics and machine learning applications in industrial settings.",Kelly Guo // Maycon da Silva Carvalho
Training Perception AI Models With Synthetic Data Generated From Isaac Sim,"In this hands-on lab, we'll using NVIDIA Omniverse and Isaac Sim to generate synthetic data for training AI models that control robotic manipulators. 
 
By the end of the lab, we'll provide hands-on experience in developing pipelines to create synthetic datasets, training perception models, and deploying these models in simulated environments before bringing them to the real world.",Rishabh Chadha
Training Humanoids With NVIDIA Isaac Lab and Apple Vision Pro,"This hands-on lab introduces robotics engineers and AI developers to advanced robot learning techniques using NVIDIA Isaac Lab and Apple Vision Pro. Participants will explore both reinforcement learning and imitation learning approaches, gaining practical experience in creating intelligent robotic systems.

This lab is ideal for robotics engineers, AI researchers, and developers interested in cutting-edge approaches to robot learning. Participants will gain hands-on experience with state-of-the-art tools and techniques, bridging the gap between virtual simulation and real-world robotic applications.",Oyindamola Omotuyi // Edith Llontop
Accelerating ROS 2 Workloads With NVIDIA GPU-Powered Libraries and AI Models,"Learn how to accelerate ROS 2 workloads using NVIDIA’s latest GPU-powered libraries for AI and robotics. This hands-on lab will explore how to leverage generative AI and GPU-accelerated ROS 2 packages to enhance robotic workloads in real time. Gain experience with optimizing ROS 2 packages for GPU acceleration, including techniques for improving performance and reducing latency in AI perception, navigation, and more. We'll also demonstrate NVIDIA Isaac's powerful AI and simulation tools, designed for seamless integration with ROS 2.",Swapnesh Wani // Hemal Shah
"The Good, the Bad, and the Ugly: Cost-Efficient LLM Inference With Quantization, Pruning, and Distillation","Dive into theoretical aspects and practical use cases for compression techniques used in creating more efficient versions of preferred models. Learn the main methods of compression — quantization, pruning, distillation — in detail, and compare trade-offs and options for jointly using multiple compression techniques. You'll become well-equipped to perform efficient inference and reduce costs when deploying LLMs. You'll understand the trade-offs in accuracy, latency, and hardware requirements for each method, and have hands-on expertise in deploying them using solutions from NVIDIA stack.",Harshita Seth // Lavinia Ghita // Ziv Ilan
Streamline Drug Discovery With NVIDIA BioNeMo NIMs and Blueprints,"Drug discovery involves several stages, including target identification, hit identification, and lead optimization, each requiring the analysis of large biochemical datasets. Artificial intelligence has already shown great promise in enhancing these stages, for which NVIDIA BioNeMo provides a platform for training, fine-tuning, and deploying LLMs and generative AI tailored for drug discovery. With BioNeMo NIMs, researchers can streamline AI workflows using cloud-native, modular components that improve the scalability and deployment of complex models. We'll highlight how BioNeMo NIMs and Blueprints can accelerate drug development, improve prediction accuracy, and enable more efficient analysis of biochemical data, showcasing real-world examples of their transformative potential in drug discovery.",Kristopher Kersten // Neel Patel (WWFO - Clara Healthcare)
Getting Started with Langflow: Build a Multi-Agent Shopping Assistant,"Harness Langflow and NVIDIA NeMo Framework to design and deploy powerful, multi-agent solutions. Join DataStax for an interactive training lab where you'll learn to design and deploy a custom shopping assistant using Langflow's intuitive drag-and-drop interface and NVIDIA NeMo Framework. From data ingestion to NVIDIA NIM model fine-tuning, uncover innovative strategies to streamline agent creation while designing intelligent agentic workflows. Participants will gain hands-on experience in configuring agents, customizing Retrieval-Augmented Generation (RAG) pipelines, and deploying a multi-agent workflow.",Kiyu Gabriel
An Introduction to NVIDIA Cosmos for Physical AI,,
Unleashing Generative AI Microservices at the Edge with NVIDIA Jetson and AWS IoT Greengrass,"Push the boundaries of edge computing by leveraging the power of NVIDIA Jetson alongside the seamless connectivity of AWS IoT Greengrass. In this hands-on lab, you’ll learn how to deploy generative AI microservices on Jetson devices, both directly and through the cloud using AWS IoT Greengrass. Engage in practical exercises to enable edge-to-cloud connectivity, optimize deployment pipelines, and orchestrate device management, all while exploring the transformative potential of generative AI at the edge and ready-to-deploy AI microservices. Don’t forget to bring your laptop for an interactive, step-by-step learning experience.",
Turn Text Into Video: Explore Animated Content Creation With Multimodal Gen AI and NVIDIA Technologies,"This training delves into multimodal generative AI, focusing on its application in video generation and its potential across various industries. We'll start by defining multimodal Gen AI and demystify the technology beyond animated visual content. We include a brief history of AI-driven video generation and an overview of current state-of-the-art solutions, highlighting differences between Gen AI for images and videos. We'll explore how to achieve temporal consistency between generated frames relying on diffusion technique.
 
 In the hands-on portion, you'll prepare a small dataset for fine-tuning a text-to-video model, gaining insights into the necessary preparations and parameters for training. While we can't conduct live training due to time and resource constraints, you'll leave with a comprehensive understanding of the process. We’ll conclude with a demonstration of running inference on an open-source text-to-video model.",Ekaterina Sirazitdinova // Oleg Sudakov
PDFSpeak: Unlocking Multimodal PDF Intelligence Through Speech,"Gain next-level insights from PDF documents just by speaking to your data. This hands-on session shows participants how to build and run PDFSpeak, an innovative approach to interacting with complex PDF documents using NVIDIA's cutting-edge AI technologies through speech, vision, and text.",Aparnaa Ramani // Arun Raman // Rachel Oberman // Shyam Renjith
"Speech-to-Omniverse: An End-to-End Pipeline Generating 3D Models Using Your Own Voice, Ninja Edition","Learn how to run an multi-modal end-to-end pipeline generating 3D assets using your own voice. We'll use state-of-the-art NIM Agent LLMs with Langchain, Langgraph, and Langserve to create an agentic pipeline transforming from text to 2D to 3D, generating 3D assets to be imported via CAD Converter, and see it come to life using Omniverse KIT SDK. In the end, you'll be able to create a 360-degree beauty shot video as trophy that you can share on social media.",Mireille Fares // Stefanie Grois // Benedikt Keyzers
Developing OpenUSD Applications for Controllable Generative AI,"In this hands-on lab, learn to develop an AI-powered application that combines the capabilities of NVIDIA NIM microservices with the NVIDIA Omniverse platform to create real-time, AI-driven experiences. You’ll start by building an Omniverse Kit-based application and then integrate NIM microservices like Edify3D and USD Search, which enables the generation of high-fidelity OpenUSD scenes and are fully controllable, allowing us to produce dynamic, AI-generated content within minutes. 
 
 By the end of this lab, you'll have hands-on experience in customizing Omniverse applications and leveraging NVIDIA’s AI technologies to push the boundaries of real-time 3D content creation. This lab is ideal for developers and content creators looking to enhance their skill set with cutting-edge tools in the rapidly evolving field of AI-generated 3D experiences.",Ashley Goldstein
Integrating Industrial Data With Digital Twins Using Microsoft Power BI and NVIDIA Omniverse,"This hands-on lab explores the integration of real-time internet-of-things (IoT) data into industrial digital twins using Microsoft Azure IoT Operations and NVIDIA Omniverse Kit SDK. Learn how to build an application for digital twins and connect virtual sensors to data streams, visualize live data within the digital twin, and implement basic analytics. By the end of this lab, you'll be able to develop a dynamic digital twin application that responds to real-time data from physical assets. This lab is ideal for developers interested in IoT integration and data visualization in industrial digital twins.",Shashi Bhushan // Martin Karlsson // Angel Mata
Developing an OpenUSD Configurator Experience for Apple Vision Pro,"Explore the future of retail with spatial computing. In this hands-on lab, we'll create an application for the Apple Vision Pro (AVP) that allows users to configure a photoreal, 3D automotive asset. This includes how to develop an application and set it up to communicate with a product configurator built with the Omniverse Kit SDK and OpenUSD. We'll also learn how to implement custom Swift UI to interact with the virtual product in real time. You'll learn to leverage advanced technologies to create immersive, interactive retail experiences.",Jen Borucki // Max Bickley
Developing Industrial Digital Twins Applications for Apple Vision Pro,"This advanced lab guides developers through creating captivating spatial experiences for Apple Vision Pro, leveraging SwiftUI and Xcode for frontend development while utilizing NVIDIA Omniverse as a powerful backend server. You’ll explore visionOS development techniques to develop immersive user interfaces for interacting with and optimizing your industrial digital twin.
 
 By the end of this lab, you'll be able to create a fully interactive and immersive spatial experience that seamlessly blends digital content with the physical space using Apple Vision Pro technology. This lab is tailored for developers interested in spatial computing and creating next-generation applications for Apple Vision Pro.",Jen Borucki // Max Bickley
Build Next-Gen Agents With Large Vision Language Models,"Vision-language models (VLM) are taking computer vision by storm, offering scalability and robust zero-shot solution for countless industries. However, there are many challenges along the way to deploying VLMs. In this workshop, we'll demystify these challenges. You'll learn what VLMs are, and we'll show you how to choose the best model, how to train and fine-tune on a small dataset, and how to deploy and use VLMs scene understanding with NVIDIA Nemo. Then we'll show different workflows for VLM deployment, with NIMs and VIA including grounding the models for more accurate results. 
 
 The workshop will be structured as follows:
 1) Introduction to VLMs (40 mins)
 a. Families of VLMs 
 b. Choice of the right VLMs
 c. Training/evaluation
 d. Fine-tuning
 e. Where to start
 2) Introduction NIMs (10 mins)
 3) Hands-on experience with VLM models through NIMs (20 mins)
 4) Introduction to VIA (10 mins)
 5) Deploy VLM with VIA reference application (20 mins)",Abubakr Karali // Debraj Sinha // Sammy Ochoa
Intro to Large Language Models: LLM Tutorial and Disease Diagnosis LLM Lab,"First we'll discuss what an LLM is and some of the strengths and weaknesses of these models, looking at a handful of models and approaches. We'll cover the difference between pre-training and fine-tuning and discuss input processing by showing how to take an input string and tokenize it into input ids. We'll present QLoRa as a means of greatly reducing computational requirements for LLM inference and fine-tuning. We'll wrap up the concepts portion of the session by discussing Hugging Face and their transformers library. 
 
 The workshop portion starts with performing inference using the Hugging Face transformers library and the Falcon-7B-Instruct model. We'll then move to fine-tuning Falcon-7B-Instruct using the MedText dataset, where the goal is to take a prompt that describes symptoms of a medical issue and generate a diagnosis of the problem, as well as steps to take to treat it.",Michaela Buchanan
Mastering NVIDIA Nsight: GPU Performance Analysis for Ray Tracing Applications,"Learn how to use NVIDIA Nsight Graphics and Nsight Systems to profile and optimize both graphics and compute workloads, focusing on ray tracing applications. You’ll analyze GPU performance through trace data from CUDA, DirectX, and Vulkan, identifying bottlenecks at the source-code and GPU assembly levels. By mastering tools like Flame Graphs and the “top-level triage” workflow, you’ll gain the skills needed to optimize shaders and CUDA code for maximum efficiency.",Aurelio Reis // Jeffrey Kiel // Axel Mamode
Mastering NVIDIA Nsight: Comprehensive Debugging for Ray Tracing Applications,"Learn to use advanced tools like NVIDIA Nsight Graphics and Nsight Aftermath to debug ray tracing applications and resolve complex bugs. We'll cover how to use the Shader Debugger to inspect variables and call stacks, use Nsight Aftermath to generate and analyze GPU crash dumps, and ensure shader configurations are correct with the Ray Tracing and API Inspectors. By the end, you’ll be able to confidently diagnose and fix bugs, improving both the reliability and performance of your applications.",Aurelio Reis // Jeffrey Kiel // Kyle Hiebel// Francesco Carucci
Learn OpenUSD: Foundations to Applied Concepts,"Join our drop-in lab to develop your OpenUSD expertise, supported by on-site experts and guided by our OpenUSD AI tutor. This self-paced experience covers foundational terminology to best practices.
 
Beginners and experienced developers will gain practical skills through hands-on exercises covering OpenUSD vocabulary, schemas, composition arcs, asset structures, data exchange, and asset modularity. 

Discover the power of NVIDIA NIM microservices for real-time guidance, or tap into the expertise of our OpenUSD specialists for in-depth knowledge. By the end of this lab, you’ll be ready to enhance your OpenUSD development and streamline workflows across industries.",Matias Codesal // Krista Glanville
Accelerate Physical AI Development Workflows with Omniverse Cloud Sensor RTX,"This hands-on lab introduces developers to NVIDIA Omniverse Cloud Sensor RTX, a set of APIs and microservices for physically accurate sensor simulation. Ideal for robotics engineers, autonomous vehicle developers, and AI specialists, this lab offers practical experience in leveraging the Sensor RTX APIs to accelerate the creation and testing of autonomous systems.",Justine Lin // Daniel Lindsey
CUTLASS Walkthrough,"Join our walkthrough for everything new in CUTLASS such as Blackwell, Flash Attention 3, and Python Interface. We'll mix lecture portions with hands-on examples.",Vijay Thakkar
Domain-Adaptive Pre-Training: Tailoring LLMs for Specialized Applications,"In this hands-on lab, explore an end-to-end approach for building domain-specific large language models. Learn how to curate domain-specific datasets, design and train custom tokenizers, and execute the pre-training process to tailor LLMs for specialized applications. You'll gain practical skills and knowledge necessary to adapt LLMs to your unique domain requirements and to real-world use cases.",Aastha Jhunjhunwala // Janaki Vamaraju // Sugandha Sharma
Build High-Performance and AI-Enabled Sensor Processing Applications,"Along with the demand for real-time insights and autonomous decision-making comes the need for scalable edge solutions that can process AI-enabled sensor data at the source and scale out to on-premises or cloud. However, several formidable challenges lie ahead:
 
 • Real-time latency requirements 
 • Complexity of building and maintaining custom pipeline for AI-enabled sensor processing
 • Hardware heterogeneity needs (for a solution not tied to a specific type of hardware)
 • Multimodality sensor processing
 • Compute-efficient visualization 
 • Integration from edge to on-premises to cloud distributed network
 • Long-term whole-stack stability
 
 Holoscan SDK is NVIDIA’s real-time, low-latency, and domain-agnostic SDK to build, deploy, and scale domain-agnostic AI-enabled sensor processing applications. We'll demonstrate how to scale with Holoscan, while stressing core components including simplification of I/O from sensor to GPU, AI inferencing and accelerated computing, and real time visualization.",Bogdan Mitrea // Maximilian Ofir
Low-Latency Numerical Computing With MatX,"This lab will introduce the Holoscan framework and demonstrate how to accelerate latency-sensitive workflows with our numerical computing API, MatX. Combining a real-time environment with a powerful Tensor language enables rapid prototyping and a seamless transition to production. Using the Holoscan SDK, we'll define a reusable and extensible low-latency computing framework using common building blocks. We'll use our environment’s tools to measure and ensure compliance with critical performance budgets. From this solid foundation, we'll build a real-world workflow using MatX, showing how its simple syntax can still provide outstanding acceleration. Finally, we'll use MatX’s extensible operators to develop our own operator, seamlessly extending MatX for a customized function.",Cliff Burdick // Dylan Eustice // Tyler Allen
Quantum Computing Meets AI: A Journey with CUDA-Q,"Embark on an exploration with CUDA-Q and learn how to use it to bring together quantum algorithms with machine learning and generative AI to elevate quantum computing. This hands-on session facilitates smooth navigation between classical and quantum domains, driving innovation in hybrid quantum-classical computing.",Pika Wang // Monica Van Dieren
Kernel Optimization for AI and Beyond: Unlocking the Power of Nsight Compute,"Learn how to unlock the full potential of NVIDIA GPUs with the powerful profiling and analysis capabilities of Nsight Compute. AI workloads are rapidly increasing the demand for GPU computing, and ensuring that they efficiently utilize all available GPU resources is essential. Nsight Compute is the most powerful tool for understanding kernel execution behavior and performance. Learn how to configure and launch profiles customized for your needs, including advice on profiling accelerated Python applications, AI frameworks like PyTorch, and optimizing Tensor Core utilization essential to modern AI performance. Learn how to debug your kernel and use the expert system built into Nsight Compute, known as “Guided Analysis,” that automatically detects common issues and directs you to the most relevant performance data all the way down to the source code level.",Felix Schmitt // Peter Labus
Find the Bottleneck: Optimize AI Pipelines With Nsight Systems,"Learn to use NVIDIA Nsight Systems to detect bottlenecks in AI pipelines and explore new features to optimize and scale the execution of your applications. We'll guide you through the performance analysis process of GPU-accelerated AI applications that run across multiple, possibly containerized, compute instances. In addition to profiling of CPU, GPU, network and I/O activity, we'll show how NVTX and the plugin mechanism enable the collection of custom data, which allows an even more comprehensive and tailored analysis on the target platform. You'll also learn about the recipe system that simplifies the identification of bottlenecks in applications running across multiple nodes.",Robert Dietrich
DevOps for Gen AI App Development: Build Scalable and Reproducible LLMOps Pipelines,"As Gen AI applications become increasingly prevalent, development practices must evolve to meet modern standards. Learn how to address the gap between data science and modern development practices. In this lab you’ll build a scalable and reproducible LLMOps development pipeline. Using off-the-shelf software, you'll integrate key tools like NeMo Customizer, NeMo Evaluator, NVIDIA NIM, and MLFlow into one GitOps-driven pipeline. By the end of this lab, you'll be equipped to support data scientists with flexible, cloud-agnostic pipelines.",Anshul Jindal // Dmitry Mironov // Martin Piercy
"“I See Dead Pipelines...Without CI/CD:"" The Gen AI Easy Button for Fine-Tuning, Evaluation, and Inference With NVIDIA NIMs and Nemo Microservices","""Dead pipelines"" — abandoned scripts that once ran parts of a workflow — plague LLM development, causing errors, delays, and wasted resources. Learn how to automate the entire LLM life cycle using CI/CD pipelines, Kubernetes, NVIDIA NIMs, and Nemo Microservices in a cloud-agnostic approach. Discover how to streamline development, fine-tuning, evaluation, and deployment of LLMs, ensuring seamless integration, validation, and deployment of updates.
 
 In this hands-on course, you'll:
 
 • Design and build a cloud-agnostic LLMOps CI/CD pipeline on Kubernetes for scalable and flexible Gen AI app deployment
 • Utilize Argo CD for declarative continuous delivery and Argo Workflows for managing complex LLM workflows
 • Leverage NVIDIA NIMs and NeMo Microservices in the end-to-end LLMOps pipeline
 • Learn how to improve development cycles, accuracy, and reliability with automated fine-tuning and continuous evaluation",Anshul Jindal // Dmitry Mironov // Martin Piercy
"Build Visual AI Agents With RAG Using NVIDIA Morpheus, RIVA, and Metropolis","Discover how to utilize NVIDIA Visual Insights Agent (VIA) microservices to create your own visual AI agents. You'll construct an agentic retrieval-augmented generation (RAG) pipeline, employing NVIDIA Morpheus SDK and NVIDIA Riva Speech Services NIMs in conjunction with VIA Microservice. We'll show you a practical example aimed at performing agentic RAG on egocentric (first-person) video feeds for dynamic, open-world QA.",Adola Adesoba // Dhruv Nandakumar
"Accelerating Linguistic Diversity: GPU-Powered Corpus Curation With NVIDIA NeMo Curator for Spanish, French, and Other Non-English Languages","Developing LLMs for non-English languages often faces the challenge of limited or imbalanced datasets. We present a cutting-edge approach to curating high-quality text corpora for languages like Spanish, French, and beyond, leveraging the power of GPU acceleration. We'll delve into the methodologies for constructing a comprehensive corpus, starting with basic heuristics for text selection and cleaning through more sophisticated techniques, such as semantic deduplication. Finally, we'll explore the innovative strategies for synthetic data generation, a crucial step in augmenting the dataset where real-world examples are scarce. 
  
 We'll show how NVIDIA's NeMo Curator can perform these tasks with remarkable speed and efficiency. You'll leave with practical insights into corpus curation workflows that can be applied to a variety of non-English languages, paving the way for more inclusive and representative language technologies.",Adam Henryk Grzywaczewski // Meriem Bendris // Miguel Martinez
Nsight Analysis System: Build custom Python analysis scripts to summarize performance and reveal bottlenecks with single and multi-node applications,"In this hands-on session, we will show how to write custom analysis scripts, called recipes, to gain deeper insights into the performance of your application using the Analysis System of the Nsight Systems profiler. We will walk through multiple examples to show the Nsight Analysis System functions that can process, filter, correlate and visualize the various hardware and software events captured by Nsight Systems. We will also show how to upgrade a single-report recipe to a multi-report recipe in order to identify performance issues in large-scale HPC and cloud applications.",Joan Yi // Jay Kreibich
Learn to Build Agentic AI Workflows for Enterprise Applications,"Using NVIDIA technologies, you will build configurable tools and workflows for agentic AI. In this class you will learn to deploy an agentic AI workflow, create tools for an AI agent, and quickly augment existing workflows with new tools. With these workflows and tools, you will increase productivity when dealing with multiple enterprise data sources.",Dhruv Nandakumar // Matt Penn
Accelerate Data Science and Leverage Foundation Models in Digital Biology,"In recent years, the intersection of artificial intelligence and biology has opened new frontiers in scientific discovery. With the ability to process vast amounts of biological data, accelerated analysis and foundation model approaches are transforming digital biology, uncovering patterns that were previously inaccessible. This training lab provides hands-on experience for how foundation models can be leveraged to analyze biological data, with a single-cell genomics example. Gain a deep understanding of the end-to-end process, from pre-processing and analyzing single-cell data to fine-tuning an LLM foundation model and evaluating its performance. Learn how foundation models can uncover biological insights, while NVIDIA’s platform accelerates the entire process, enabling fast and scalable results. Get an overview of relevant NVIDIA solutions in digital biology, such as Parabricks, Vista2D, RAPIDS, and BioNeMo, and acquire the practical skills to use them to tackle complex biological challenges with GPUs.",Gary Burnnett // Neel Patel
Structure From Chaos: Accelerate GraphRAG With cuGraph and NVIDIA NIM,"Learn how to integrate large language models (LLMs) with NVIDIA Inference Microservices (NIM) and cuGraph to create cutting-edge, graph-based AI solutions for handling complex, interconnected data. We'll cover fine-tuning techniques, Langchain agents, and GPU-accelerated graph analytics to enhance AI capabilities and retrieval-augmented generation (RAG) evaluation.",Benika Hall / Christopher Brissette // Rohan Rao // Sunil Patel
Accelerate Data Analytics on GPUs With the RAPIDS Accelerator for Apache Spark,"The RAPIDS Accelerator for Apache Spark leverages the distributed big data processing framework of Spark along with the power of GPUs to greatly speed up ETL and analytics workloads while reducing cost. In this training lab, we'll walk through the RAPIDS Accelerator for Apache Spark, including running SQL queries on CPU and GPU in Spark and also diving into the toolset that helps enable success with the RAPIDS Accelerator for Apache Spark.",Ahmed Hussein // Lee Yang // Matt Ahrens
Apply Multi-Node Multi-GPU Computing to HPO and Inference,"With ever-increasing amounts of data and limited compute resources, training competitive ML models end-to-end can take hours, days, or even weeks. Parallel computing offers a solution. Join us to learn how to reduce your end-to-end ML pipeline and increase model accuracy by parallelizing and distributing model training, hyperparameter optimization, and inference across GPUs.",Miguel Martinez // Nick Venanzi // Roman Yokunda Enzmann
Use GPUs to Accelerate Vector Databases,"Vector databases are a hot topic today for semantic search, and they're powering everything from generative AI workloads to recommender systems. This lab will provide hands-on instruction for optimizing vector database workloads on the GPU, including (1) optimizing ingest and index creation at scale, (2) choosing the best indexes for your data, and (3) tuning the indexes to trade off search speed and quality.",Corey Nolet // Julio Perez // Nathan Stephens
Learn how Gen AI Image Pipelines are Shaping up in Various industries With Hands-on Workflows,"Generating and understanding images are the two core areas of image-based workflows. We'll cover how the media & entertainment, retail/fashion, and healthcare industries are leveraging diffusion and transformer models together for Gen AI workflows. We'll emphasize emerging use cases while addressing how conventional computer vision pipelines are impacted by Gen AI, and its consequences. NIMs, ComfyUI, and TensorRT are the core components to demonstrate these workflows.",Avinash Chakravarthi // Sakshi Tyagi // Shreyans Dhankhar
Empower Digital Humans With RAG and Multi-Modal AI,"Building on the creation of digital avatars, this lab delves into enhancing digital humans with intelligence and contextual awareness. Learn to implement retrieval-augmented generation (RAG) to provide knowledge and context to digital avatars. We'll also cover the integration of multi-modal vision-language models (VLMs) that support images, video, and text, and explore the combination of large language models (LLMs) and vision transformers (ViT) to create more sophisticated and interactive digital human experiences. In the end, you'll be able to imbue your digital avatars with advanced AI capabilities, enabling more natural and informed interactions.",Rohit Vaswani
Build an Industrial Co-Pilot for Process Monitoring and Quality Control,"Powered by AI, industrial co-pilots are revolutionizing the way workers perform manual tasks, significantly improving operational efficiency and quality. This lab will demonstrate how intelligent assistants use computer vision and natural language processing to monitor and optimize repetitive processes. These processes are often defined by Standard Operating Procedures, step-by-step instructions that are essential in maintaining consistency and quality in industrial settings. Integrating industrial co-pilots into these processes can help guide workers through tasks and identify errors in real-time, enhancing productivity and yields.

You'll learn how to:
Use Vision Language Models (VLMs) and Large Language Models (LLMs) to build industrial co-pilots.
Customize and optimize AI models for any use case, process, and industry.
Curate and prepare data for model customization.
Optimize and deploy for your industrial environment.",Chintan Shah
Best Practices in Feature Engineering for Tabular Data With GPU Acceleration,"Feature engineering is an important component in (tabular) machine learning solutions, which can be easily integrated into existing models and boost model accuracy. The tabular data structure limits the models' capabilities to learn the relationships between features, so adding handcrafted features can significantly improve model performance. We'll teach best practices for feature engineering techniques specific to tabular data building off our teams' collective experience competing in data science competitions such as Kaggle and RecSys. Learn how to create features from categorical, numerical, and time-series data, and accelerate your data frame operations on GPU. We'll use RAPIDS, an open-source software that accelerates the whole data science pipeline from data preprocess/engineering to machine learning on GPU.",Benedikt Schifferer // Chris Deotte // Ronay Ak
Bring Accelerated Computing to Data Science in Python,"With datasets growing rapidly in volume, velocity, and veracity, the demand for more efficient data processing has never been higher. This workshop walks through how to apply open-source GPU accelerators from the NVIDIA RAPIDS project for common Python data science workflows.",Kevin Lee
Accelerating Clustering Algorithms to Achieve the Highest Performance,"Clustering is commonly applied across industries for applications such as recommendation systems and fraud detection. In this lab, through examples, we will discuss techniques to accelerate common clustering algorithms and tips/tricks to derive the highest performance.",Allison Ding
Analyzing and Visualizing Large Data Interactively using Accelerated Computing,In this lab we will explore how to accelerate visualization of large data using common visualization packages used in key industries. Such visualizations can deliver powerful insights in an intuitive way and can make results more approachable to a wider audience.,Allison Ding
Learn OpenUSD: Robotics Best Practices,"In this course, we will be expanding on the concepts of assets from our previous Learn OpenUSD courses and applying them within the domain of robotics. We’ll learn about the benefits of a robot asset structure in OpenUSD and learn best practices by studying the asset structure utilized by the URDF Importer in Isaac Sim. We will gain insights on various optimizations that can be performed on a robot asset and experiment with the different techniques like mesh merging and instancing. Lastly, we will assemble the robot asset and an environment to construct a robot training scene.",Renato Gasoto
Robotic Simulations With Reinforcement Learning at Scale: Harness the Power of NVIDIA Isaac Lab on AWS,"Simulation-based reinforcement learning greatly benefits the field of robotics, enabling models to learn complex tasks quickly. NVIDIA Isaac Lab offers a reinforcement learning environment to train and test robots in realistic simulated environments using physics-based rendering. We'll dive deeper into NVIDIA’s Isaac Lab, AWS Batch, and Amazon EC2 instances powered by NVIDIA GPUs, and highlight the advantages of robotic simulation on AWS. Through hands-on labs, you’ll learn distributed training for robots across multiple GPU nodes, leveraging AWS Batch to accelerate performance. Additionally, we’ll explore the crucial sim-to-real transition, sharing insights and strategies for effectively translating simulation learnings to real-world robotic applications.",Abhishek Srivastav // Shaun Kirby (Note: Aakriti Srivastava IN does not seem to know about this course)
Create and Manage On-Prem AI Clusters With Base Command Manager,"This lab will introduce the NVIDIA Base Command Manager software and describe the best practices for managing AI infrastructure. You’ll gain hands-on experience with provisioning cluster nodes, managing software images, creating users and groups, deploying Kubernetes, running a containerized workload, building a custom monitoring script, and configuring nodes with GPUs. We'll cover both Base Command Manager, which is included in the NVIDIA DGX SW stack, and Base Command Manager Essentials, which is included in NVIDIA AI Enterprise.",Max Steele // Terrell Bennett
Use NVIDIA Base Command Manager and Run:ai to Fuel Your AI Superpowers,"In this hands-on DLI session, we'll show you how to harness the power of NVIDIA Base Command Manager and Run:ai to fuel your AI factory. You'll start with a cluster managed by Base Command Manager and learn how to use it to install Run:ai, unlocking its full potential to increase utilization of your AI resources. By the end of this session, you'll be able to transform your AI cluster from hard-to-use to easily manageable by administrators and data scientists alike. Whether you're looking to simplify your AI workflow or take your AI factory to the next level, this session is perfect for using NVIDIA Base Command Manager and Run:ai to power your AI endeavors.",Jeff Weiss // Scott Ellis
Make Retrieval Better: Fine-Tuning an Embedding Model for Domain-Specific RAG,"LLMs power AI applications like conversational chatbots and content generators, but are constrained by their training data. This might lead to hallucinations in content generation, which requires up-to-date or domain-specific information. Retrieval augmented generation (RAG) addresses this issue by enabling LLMs to access external context without modifying model parameters. Embedding or dense retrieval models are a key component of a RAG pipeline for retrieving relevant context to the LLM. However, an embedding model’s effectiveness to capture the unique characteristics of the custom data hinges on the quality and domain relevance of its training data. Fine-tuning embedding models is gaining interest to provide more accurate and relevant responses tailored to users’ specific domain. 
 
 In this tutorial, you'll learn to generate a synthetic dataset with question-context pairs from a domain-specific corpus, and process the data for fine-tuning. Then, fine-tune a text embedding model using synthetic data and evaluate it.",Benedikt Schifferer // Gabriel Moreira // Ronay Ak
"Address Complex/Logical Tasks With Conversational AI: Multi-Agent, Multi-Turn Framework From Scratch","Learn to build an agent framework to tackle the multi-turn complex task, how to add tools, and multi-turn agents behavior. Learn how to build conversational AI agents that can tackle complex tasks with ease, and explore new techniques for multi-turn conversations and persona-based interactions.",Sagar Desai
Applying AI Weather Models With NVIDIA Earth-2,Explore how NVIDIA Earth-2 facilitates efficient weather and climate modeling. Learn how to run a large and growing stack of global AI weather forecasting models and how downscaling models generate super-resolution outputs. Discover use cases and applications benefiting the most from this emerging technology.,Georg Ertl // Jussi Leinonen // Stefan Weissenberger
The Speed of Thought: Navigate LLM Inference Autoscaling for a Gen AI Application Toward Production,Learn how to choose the autoscaling hyperparameters for your LLM applications by understanding the key metrics during inference. Gain essential tools to optimize latency and throughput by running and dissecting LLM inference benchmarks. See how NVIDIA's benchmarking software can be leveraged to make an informed decision about the Kubernetes deployment of your Gen AI application. You'll acquire best practices and tips to allow you to bring low latency at unmatched cost-effectiveness to your NIM applications for production.,Dmitry Mironov // Sergio Perez // Mohak Chadha
007 Evaluations for Your Customer Assistant LLM Agent: No Time for Hallucinations,"Evaluate and optimize an LLM customer assistant, ensuring it performs robustly, accurately, and with no hallucinations in real-world scenarios. Leverage the NeMo Evaluator Microservice to create unit tests to track Gen AI model quality continuously during the development: 
 
 • Optimize accuracy in your local languages for multilingual deployments and AI sovereignty
 • Employ LLM-as-a-judge to ensure truthfulness and toxicity
 • Evaluate end-to-end RAG applications
 
 Master techniques for visualizing evaluation results, and use these insights to make informed decisions and improvements to your LLM agents. You'll have access to a k8s deployment of NeMo Microservices pipeline and NIM, which will be ready for experimentation.",Dmitry Mironov // Sergio Perez // Ziv Ilan
From NeRF to 3DGS: Exploring Advanced Methods for High-Quality Static and Dynamic Scene Reconstruction in Interactive 3D Worlds,"In this training lab, we'll explore the latest techniques in 3D scene creation using neural radiance fields (NeRF) and 3D Gaussian splatting (3DGS). These methods use machine learning to create detailed 3D scenes from just a few images. Learn how to model dynamic scenes where objects can move and rotate while keeping their color, opacity, and size consistent. We’ll also cover how to combine elements from different scenes and add new objects to moving scenes, like attaching a hat to a character that changes position. Gain practical skills in using NeRF and 3DGS to create and manage both static and dynamic 3D scenes.",Andrea Pilzer // Mireille Fares
Blueprints for Success: Take the Red Pill — Navigating NIM Agent Workflows for Real-World Multimodal Retrieval,"In this comprehensive course, you'll delve into the real-world applications of multimodal retrieval-augmented generation (RAG). Through a series of hands-on modules, learn how to leverage NIM agent blueprints as a one-stop solution for your AI projects. Much of the course is a deep dive into a real-life multimodal RAG application at scale, utilizing NVIDIA NIMs. You'll gain the knowledge and skills needed to implement and optimize multimodal data ingestion, embedding, and retrieval. You'll also learn how NVIDIA Blueprints can guide your AI solution from proof of concept (POC) to production using self-hosted microservices. This holistic approach ensures that you are equipped to handle every stage of the AI development lifecycle. In the end, you'll have a solid understanding of NIM agent workflows and be able to apply them effectively in real-world scenarios, taking your AI projects to the next level.",Natalia Segal // Rita Fernandes Neves // Ziv Ilan
Evaluating RAG and Semantic Search Systems,"As adoption of LLMs and retrieval-augmented generation (RAG) becomes more prevalent in enterprise, the demand for robust evaluation arises, ensuring these new tools meet the high regulatory standards of various industries. Gain an in-depth understanding of the unique requirements as well as practical tools to robustly evaluate such systems addressing the complex nature of the underlying data. We'll introduce evaluation techniques addressing domain-specific language and knowledge, specific evaluation metrics, and independent assessment of the retrieval and generation steps, all while taking temporal information into account.",Amit Bleiweiss
Accelerating Portfolio Optimization,"Join our in-depth exploration of cutting-edge techniques to accelerate portfolio optimization on GPUs. We'll unpack how to formulate optimization problems in terms of risk-reward trade-offs under various constraints. We'll discuss how to transform traditionally sequential optimization algorithms into parallel ones that can leverage GPU acceleration to manage complex, high-dimensional investment portfolios efficiently. Concrete examples using FX options and equity portfolios will be provided.",Ioana Boier // Peihan Huo // Yigal Jhirad
Scaling Inference Using NIM Through A Serverless NCP SaaS Platform,"We'll train you to scale your Gen AI workload and create a software-as-a-service (SaaS) serverless platform. We'll use NIMs of an open-source LLM, scaling it using open-source technologies like Kubernetes, Ray, and KServe, and we'll demonstrate the usage of NVCF. We'll show you how to obtain GPU utilization metrics using Grafana and Prometheus, autoscaling compute resources based on inflight demand and defining best practices around efficiently using the underlying abstracted GPU infrastructure based on NCP RA.",Anish Mukherjee // Jalaj Thanaki
Automate 5G Network Configurations With NVIDIA AI LLM Agents and Kinetica Accelerated Database,"Learn how to create AI agents using LangGraph and NVIDIA NIM to automate 5G network configurations. You'll deploy LLM agents to monitor real-time network quality of service (QoS) and dynamically respond to congestion by creating new network slices. LLM agents will process logs to detect when QoS falls below a threshold, then automatically trigger a new slice for the affected user equipment. Using graph-based models, the agents understand the network configuration, identifying impacted elements. This ensures efficient, AI-driven adjustments that consider the overall network architecture.
 
 We'll use the Open Air Interface 5G lab to simulate the 5G network, demonstrating how AI can be integrated into real-world telecom environments. You'll also gain practical knowledge on using Python with LangGraph and NVIDIA AI endpoints to develop and deploy LLM agents that automate complex network tasks.",Amparo Canaveras // Swastika Dutta
Build an AI Research Assistant with NVIDIA AI Blueprints,"NVIDIA AI Blueprints show developers how to build complex solutions using NVIDIA software. In this hands-on training lab, attendees will build an interactive AI-powered research assistant that includes:
- a stylized digital human avatar for interactivity
- a RAG system for multimodal document understanding
- an AI agent that will research topics and discuss its findings",Jacob Liberman